{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the scripts to the notebooks path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 8&9\\Adey-Innovations-Fraud-Detection\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "scripts_path = os.path.join(parent_dir, 'scripts')\n",
    "\n",
    "# Insert the path to the parent directory\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Insert the path to the Scripts directory\n",
    "sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to the csv files\n",
    "COUNTRY_IP_DATA = \"../data/IpAddress_to_Country.csv\"\n",
    "FRAUD_DATA = \"../data/Fraud_Data.csv\"\n",
    "CREDIT_DATA = \"../data/creditcard.csv\"\n",
    "\n",
    "# load the data into pandas dataframes\n",
    "country_ip_mapping = pd.read_csv(COUNTRY_IP_DATA)\n",
    "fraud_data = pd.read_csv(FRAUD_DATA)\n",
    "credit_data = pd.read_csv(CREDIT_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First pass the data through the feature egineering pipeline. It contains the following processes.\n",
    "\n",
    "merege ip and fraud data -> calculate transaction velocity and frequency -> break down date features -> handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FeatureEngineering.feature_enginering_pipeline(data=fraud_data, ip_mapping=country_ip_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.utils import load_pickle, pickle_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the root path where to export/load pickeled objects from\n",
    "EXPORT_PATH_ROOT = \"../feature_store\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First for the credit card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "credit_card_features = [column for column in credit_data.columns if column not in [\"Class\"]]\n",
    "\n",
    "# define target \n",
    "credit_card_target = \"Class\"\n",
    "\n",
    "# save the feature into pickle file\n",
    "feature_save_path = os.path.join(EXPORT_PATH_ROOT, 'credit_features.pkl')\n",
    "pickle_object(file_path=feature_save_path, object=credit_card_features)\n",
    "\n",
    "# save the target into a pickle file\n",
    "target_save_path = os.path.join(EXPORT_PATH_ROOT, 'credit_target.pkl')\n",
    "pickle_object(file_path=target_save_path, object=credit_card_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the features and targets\n",
    "credit_X = credit_data[credit_card_features]\n",
    "credit_y = credit_data[credit_card_target]\n",
    "\n",
    "# split them into training and testing features\n",
    "credit_train, credit_test, credit_y_train, credit_y_test = train_test_split(credit_X, credit_y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "fraud_features = [column for column in data.columns if column not in [\"class\", \"user_id\", \"device_id\"]]\n",
    "\n",
    "# define targets\n",
    "fraud_targets = \"class\"\n",
    "\n",
    "# save the feature into pickle file\n",
    "feature_save_path = os.path.join(EXPORT_PATH_ROOT, 'fraud_features.pkl')\n",
    "pickle_object(file_path=feature_save_path, object=fraud_features)\n",
    "\n",
    "# save the target into a pickle file\n",
    "target_save_path = os.path.join(EXPORT_PATH_ROOT, 'fraud_target.pkl')\n",
    "pickle_object(file_path=target_save_path, object=fraud_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the features and targets\n",
    "fraud_X = data[fraud_features]\n",
    "fraud_y = data[fraud_targets]\n",
    "\n",
    "# split them into training and testing features\n",
    "fraud_train, fraud_test, fraud_y_train, fraud_y_test = train_test_split(fraud_X, fraud_y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalize the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the root path to store scalers and numerical encoders in\n",
    "ENCODERS_PATH_ROOT = \"../scalers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First normalize the credit  scoring numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the numerical features in the credit card data using the training data and save the scaler to be used during inference\n",
    "credit_train, credit_numerical_scaler = FeatureEngineering.normalize_numerical_features(data=credit_train)\n",
    "credit_test = credit_numerical_scaler.transform(X=credit_test)\n",
    "\n",
    "# save the scaler\n",
    "pickle_object(file_path=os.path.join(ENCODERS_PATH_ROOT, 'credit_scaler.pkl'), object=credit_numerical_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now normalize the fraud numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the numerical features in the fraud data using training data and save the scaler to be used during inference\n",
    "fraud_train_numeric_scaled, fraud_numerical_scaler = FeatureEngineering.normalize_numerical_features(data=fraud_train)\n",
    "scaled_columns = fraud_numerical_scaler.get_feature_names_out()\n",
    "fraud_test_numeric_scaled = fraud_numerical_scaler.transform(X=fraud_test[scaled_columns])\n",
    "\n",
    "# replace the numerical columns with the scaled ones\n",
    "fraud_train[scaled_columns] = fraud_train_numeric_scaled[scaled_columns]\n",
    "fraud_test[scaled_columns] = fraud_test_numeric_scaled\n",
    "\n",
    "# save the numeric columns that are scaled into pickle files\n",
    "pickle_object(file_path=os.path.join(EXPORT_PATH_ROOT, 'scaled_numerical_features.pkl'), object=scaled_columns)\n",
    "\n",
    "# save the scaler\n",
    "pickle_object(file_path=os.path.join(ENCODERS_PATH_ROOT, 'fraud_scaler.pkl'), object=fraud_numerical_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now encode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import use_label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit data is skipped because all of its values are numerical data. So no need to encode it. \n",
    "Only the fraud data is going to have to categorical columns to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features using data from training, obtain the encoders for each categorical columns\n",
    "fraud_train, categorical_encoder = FeatureEngineering.encode_categorical_data(data=fraud_train)\n",
    "\n",
    "# encode categorical features of the testing data\n",
    "for categorical_column in categorical_encoder:\n",
    "    fraud_test[categorical_column] = use_label_encoder(data=fraud_test[categorical_column], encoder=categorical_encoder[categorical_column])\n",
    "\n",
    "# save the categorical column encoders in pickle files\n",
    "pickle_object(file_path=os.path.join(ENCODERS_PATH_ROOT, 'categorical_encoder.pkl'), object=categorical_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up mlflow for tracking experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.modeling import ModelingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ModelingPipeline(\n",
    "    x_train=fraud_train,\n",
    "    x_test=fraud_test,\n",
    "    y_train=fraud_y_train,\n",
    "    y_test=fraud_y_test,\n",
    "    tracking_uri=\"sqlite:///../mlflow_runs/mlflow.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an mlflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = pipeline.create_experiment(experiment_name='Experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-29 16:23:07,702] A new study created in memory with name: no-name-a423dab5-ebdc-49c9-8bc4-916de027c117\n",
      "[I 2024-10-29 16:23:07,854] Trial 0 finished with value: 0.9068690166321084 and parameters: {'C': 13.18082849075773, 'max_iter': 479}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:07,990] Trial 1 finished with value: 0.9068690166321084 and parameters: {'C': 1.3845414368352644e-05, 'max_iter': 191}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:08,126] Trial 2 finished with value: 0.9068690166321084 and parameters: {'C': 0.0645037673749587, 'max_iter': 179}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:08,266] Trial 3 finished with value: 0.9068690166321084 and parameters: {'C': 0.02120778833695094, 'max_iter': 396}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:08,405] Trial 4 finished with value: 0.9068690166321084 and parameters: {'C': 74.61891686416675, 'max_iter': 212}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:08,544] Trial 5 finished with value: 0.9068690166321084 and parameters: {'C': 1.8893859024548971, 'max_iter': 202}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:23:08,693] Trial 6 finished with value: 0.9068690166321084 and parameters: {'C': 0.15455422894688828, 'max_iter': 199}. Best is trial 0 with value: 0.9068690166321084.\n",
      "2024/10/29 16:23:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2024-10-29 16:23:11,377] A new study created in memory with name: no-name-99c42ce3-dff4-47d1-abf5-cf519a0ef086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training Logistic Regressor ####\n",
      "Best parameters for Logistic Regressor: {'C': 13.18082849075773, 'max_iter': 479}\n",
      "Test accuracy with best parameters: 0.9068690166321084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-29 16:23:12,411] Trial 0 finished with value: 0.9503242599373538 and parameters: {'max_depth': 15, 'min_samples_split': 4}. Best is trial 0 with value: 0.9503242599373538.\n",
      "[I 2024-10-29 16:23:13,673] Trial 1 finished with value: 0.9461110866016677 and parameters: {'max_depth': 20, 'min_samples_split': 7}. Best is trial 0 with value: 0.9503242599373538.\n",
      "[I 2024-10-29 16:23:15,168] Trial 2 finished with value: 0.9418096792694225 and parameters: {'max_depth': 26, 'min_samples_split': 8}. Best is trial 0 with value: 0.9503242599373538.\n",
      "[I 2024-10-29 16:23:16,669] Trial 3 finished with value: 0.9415449772797458 and parameters: {'max_depth': 25, 'min_samples_split': 5}. Best is trial 0 with value: 0.9503242599373538.\n",
      "[I 2024-10-29 16:23:16,983] Trial 4 finished with value: 0.9549786032558345 and parameters: {'max_depth': 4, 'min_samples_split': 8}. Best is trial 4 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:23:18,068] Trial 5 finished with value: 0.9480522345259629 and parameters: {'max_depth': 17, 'min_samples_split': 2}. Best is trial 4 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:23:19,284] Trial 6 finished with value: 0.9469934265672564 and parameters: {'max_depth': 19, 'min_samples_split': 6}. Best is trial 4 with value: 0.9549786032558345.\n",
      "2024/10/29 16:23:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2024-10-29 16:23:21,328] A new study created in memory with name: no-name-a76e2680-0c82-41d7-a80f-43f08309444f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training Decision Tree ####\n",
      "Best parameters for Decision Tree: {'max_depth': 4, 'min_samples_split': 8}\n",
      "Test accuracy with best parameters: 0.9549786032558345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-29 16:23:32,186] Trial 0 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 92, 'max_depth': 11}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:23:39,865] Trial 1 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 292, 'max_depth': 2}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:23:47,389] Trial 2 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 74, 'max_depth': 9}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:24:30,724] Trial 3 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 191, 'max_depth': 31}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:24:50,750] Trial 4 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 173, 'max_depth': 11}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:24:56,879] Trial 5 finished with value: 0.9549786032558345 and parameters: {'n_estimators': 80, 'max_depth': 7}. Best is trial 0 with value: 0.9549786032558345.\n",
      "[I 2024-10-29 16:26:33,954] Trial 6 finished with value: 0.9550006617549742 and parameters: {'n_estimators': 416, 'max_depth': 30}. Best is trial 6 with value: 0.9550006617549742.\n",
      "2024/10/29 16:28:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2024-10-29 16:28:10,605] A new study created in memory with name: no-name-b0dfb01b-12fc-4c54-94a6-2dfe27a074e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training Random Forest ####\n",
      "Best parameters for Random Forest: {'n_estimators': 416, 'max_depth': 30}\n",
      "Test accuracy with best parameters: 0.9550006617549742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-29 16:28:14,444] Trial 0 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 91, 'alpha': 0.00018976386976261514, 'max_iter': 398}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:16,599] Trial 1 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 110, 'alpha': 0.08849964685880911, 'max_iter': 300}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:19,114] Trial 2 finished with value: 0.09313098336789165 and parameters: {'hidden_layer_sizes': 95, 'alpha': 0.0004354633894725343, 'max_iter': 242}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:21,152] Trial 3 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 83, 'alpha': 0.00024174625418044455, 'max_iter': 56}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:23,390] Trial 4 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 112, 'alpha': 0.0035058833367899744, 'max_iter': 91}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:25,170] Trial 5 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 64, 'alpha': 0.018651690432184575, 'max_iter': 81}. Best is trial 0 with value: 0.9068690166321084.\n",
      "[I 2024-10-29 16:28:27,860] Trial 6 finished with value: 0.9068690166321084 and parameters: {'hidden_layer_sizes': 137, 'alpha': 0.02482526302631828, 'max_iter': 221}. Best is trial 0 with value: 0.9068690166321084.\n",
      "2024/10/29 16:28:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 16:28:33 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.17.0, but the installed version is 2.18.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n",
      "2024/10/29 16:28:33 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2024/10/29 16:28:33 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training MLP ####\n",
      "Best parameters for MLP: {'hidden_layer_sizes': 91, 'alpha': 0.00018976386976261514, 'max_iter': 398}\n",
      "Test accuracy with best parameters: 0.9068690166321084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3268/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 1185376.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 1182866.8750 - val_accuracy: 0.9069 - val_loss: 441946.2500\n",
      "Epoch 2/10\n",
      "\u001b[1m3281/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8276 - loss: 804954.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8276 - loss: 804614.4375 - val_accuracy: 0.0932 - val_loss: 194714.7031\n",
      "Epoch 3/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8284 - loss: 652226.9375 - val_accuracy: 0.9069 - val_loss: 549352.3750\n",
      "Epoch 4/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8279 - loss: 612069.5000 - val_accuracy: 0.0932 - val_loss: 1266002.7500\n",
      "Epoch 5/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 456928.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8267 - loss: 456932.0625 - val_accuracy: 0.9062 - val_loss: 87878.7422\n",
      "Epoch 6/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8307 - loss: 423133.6250 - val_accuracy: 0.0934 - val_loss: 483215.5625\n",
      "Epoch 7/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 364175.6562 - val_accuracy: 0.9065 - val_loss: 247148.7344\n",
      "Epoch 8/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 270074.5625 - val_accuracy: 0.9059 - val_loss: 124620.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:29:12 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2024/10/29 16:29:12 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:29:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1417/1417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:29:17 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:29:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 16:29:20 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.17.0, but the installed version is 2.18.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n",
      "2024/10/29 16:29:20 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2024/10/29 16:29:20 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training CNN ####\n",
      "Test accuracy: 0.9062072616579168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3273/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8279 - loss: 112680.4609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 111879.4453 - val_accuracy: 0.9069 - val_loss: 1776.6578\n",
      "Epoch 2/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 2317.8560 - val_accuracy: 0.9069 - val_loss: 2442.8501\n",
      "Epoch 3/10\n",
      "\u001b[1m3275/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 623.5281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 621.2032 - val_accuracy: 0.0932 - val_loss: 286.3668\n",
      "Epoch 4/10\n",
      "\u001b[1m3284/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 111.8548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 111.7167 - val_accuracy: 0.9069 - val_loss: 138.3047\n",
      "Epoch 5/10\n",
      "\u001b[1m3299/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 76.9594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 76.9077 - val_accuracy: 0.2904 - val_loss: 0.7608\n",
      "Epoch 6/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 5.1704 - val_accuracy: 0.9069 - val_loss: 1.6481\n",
      "Epoch 7/10\n",
      "\u001b[1m3271/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 16.4158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 16.3128 - val_accuracy: 0.9056 - val_loss: 0.4853\n",
      "Epoch 8/10\n",
      "\u001b[1m3286/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.5895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.5898 - val_accuracy: 0.9069 - val_loss: 0.3125\n",
      "Epoch 9/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.7377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.7376 - val_accuracy: 0.9067 - val_loss: 0.3038\n",
      "Epoch 10/10\n",
      "\u001b[1m3281/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.6135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.6137 - val_accuracy: 0.9481 - val_loss: 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:30:20 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2024/10/29 16:30:20 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:30:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1417/1417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:30:25 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:30:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/29 16:30:29 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.17.0, but the installed version is 2.18.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n",
      "2024/10/29 16:30:29 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2024/10/29 16:30:29 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training RNN ####\n",
      "Test accuracy: 0.9481404685225218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m3300/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.2062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.2062 - val_accuracy: 0.9550 - val_loss: 0.1814\n",
      "Epoch 2/7\n",
      "\u001b[1m3304/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1724 - val_accuracy: 0.9550 - val_loss: 0.1646\n",
      "Epoch 3/7\n",
      "\u001b[1m3288/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1572 - val_accuracy: 0.9550 - val_loss: 0.1633\n",
      "Epoch 4/7\n",
      "\u001b[1m3297/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1576 - val_accuracy: 0.9550 - val_loss: 0.1627\n",
      "Epoch 5/7\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1568 - val_accuracy: 0.9550 - val_loss: 0.1631\n",
      "Epoch 6/7\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1575 - val_accuracy: 0.9550 - val_loss: 0.1628\n",
      "Epoch 7/7\n",
      "\u001b[1m3292/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [absl] You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1583 - val_accuracy: 0.9550 - val_loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:31:47 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2024/10/29 16:31:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:31:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1417/1417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 16:31:53 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/10/29 16:31:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Finished Training LSTM ####\n",
      "Test accuracy: 0.9549786032558345\n",
      "#### Finished Training All Models ####\n"
     ]
    }
   ],
   "source": [
    "pipeline.train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the best model from mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 19/19 [00:00<00:00, 978.16it/s] \n"
     ]
    }
   ],
   "source": [
    "pipeline.log_best_model(export_path='../model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
