{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the scripts to the notebooks path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 8&9\\Adey-Innovations-Fraud-Detection\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "scripts_path = os.path.join(parent_dir, 'scripts')\n",
    "\n",
    "# Insert the path to the parent directory\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Insert the path to the Scripts directory\n",
    "sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to the csv files\n",
    "COUNTRY_IP_DATA = \"../data/IpAddress_to_Country.csv\"\n",
    "FRAUD_DATA = \"../data/Fraud_Data.csv\"\n",
    "CREDIT_DATA = \"../data/creditcard.csv\"\n",
    "\n",
    "# load the data into pandas dataframes\n",
    "country_ip_mapping = pd.read_csv(COUNTRY_IP_DATA)\n",
    "fraud_data = pd.read_csv(FRAUD_DATA)\n",
    "credit_data = pd.read_csv(CREDIT_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First pass the data through the feature egineering pipeline. It contains the following processes.\n",
    "\n",
    "merege ip and fraud data -> calculate transaction velocity and frequency -> break down date features -> handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FeatureEngineering.feature_enginering_pipeline(data=fraud_data, ip_mapping=country_ip_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.utils import load_pickle, pickle_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the root path where to export/load pickeled objects from\n",
    "EXPORT_PATH_ROOT = \"../feature_store\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First for the credit card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "credit_card_features = [column for column in credit_data.columns if column not in [\"Class\"]]\n",
    "\n",
    "# define target \n",
    "credit_card_target = \"Class\"\n",
    "\n",
    "# save the feature into pickle file\n",
    "feature_save_path = os.path.join(EXPORT_PATH_ROOT, 'credit_features.pkl')\n",
    "pickle_object(file_path=feature_save_path, object=credit_card_features)\n",
    "\n",
    "# save the target into a pickle file\n",
    "target_save_path = os.path.join(EXPORT_PATH_ROOT, 'credit_target.pkl')\n",
    "pickle_object(file_path=target_save_path, object=credit_card_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the features and targets\n",
    "credit_X = credit_data[credit_card_features]\n",
    "credit_y = credit_data[credit_card_target]\n",
    "\n",
    "# split them into training and testing features\n",
    "credit_train, credit_test, credit_y_train, credit_y_test = train_test_split(credit_X, credit_y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "fraud_features = [column for column in data.columns if column not in [\"class\", \"user_id\", \"device_id\"]]\n",
    "\n",
    "# define targets\n",
    "fraud_targets = \"class\"\n",
    "\n",
    "# save the feature into pickle file\n",
    "feature_save_path = os.path.join(EXPORT_PATH_ROOT, 'fraud_features.pkl')\n",
    "pickle_object(file_path=feature_save_path, object=credit_card_features)\n",
    "\n",
    "# save the target into a pickle file\n",
    "target_save_path = os.path.join(EXPORT_PATH_ROOT, 'fraud_target.pkl')\n",
    "pickle_object(file_path=target_save_path, object=credit_card_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the features and targets\n",
    "fraud_X = data[fraud_features]\n",
    "fraud_y = data[fraud_targets]\n",
    "\n",
    "# split them into training and testing features\n",
    "fraud_train, fraud_test, fraud_y_train, fraud_y_test = train_test_split(fraud_X, fraud_y, test_size=0.3, random_state=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
